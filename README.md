# Encoder-Decoder and Fast Marching for segmentation of blood vessels in Lung tissue
This repository contains the code for the Master's Thesis *Title* written by Adam Svedberg and Sebastian Petersson on the Institution of Mathematical Statistics at the Faculty of Engineering at Lund University. 

The file pre-process.py in the main folder handles pre-processesing and transforms volumes by size $2560 \times 2560 \times 2160$ into $1024 \times 1024 \times 1024$ as well as downsampling the volumes from 16 bit to 8 bit depth. It then saves these volumes to the folder "3d-stacks/". It collects the original volumes from "images/{file_name}/rec_16bit_Paganin_0/". Towards the end of the code (row ~80) it can be instructed to go through all subfolders with images in the folder "images/" or certain file_names in the folder.

In the file "FMM_segmentation/main.py" the active volume to segment can be chosen at the top of the main-function (line 102). When running main.py it then collects seed points from the folder "seed_points/" according to matching name (i.e. for r01_ it collects the file r01_seed_points.csv) and starts the FMM segmentation from these seed points. It expects the seed_points to have four columns in the order (index, x, y, z) where index is not used. It has some flexibility regarding columns. 

By running "ML_segmentation/train.py" the ML model is trained on the data it is instructed to use via "ML_segmentation/configuration.py" (~line 14). It collects the (pre-processed) images from the folder "3d-stacks/{file_name}/", and the masks from the folder "results/". It then saves three models in the folder "checkpoints/", the one from the last epoch, the one with the best recall metric and the one with the best validation loss (it compares the saved models after each epoch and updates which one to save). 

In order to visualise and evaluate a trained model the file "ML_segmentation/orthagonal_evaluation.py" should be run. This program evaluates volumes accross the x, y, and z-axes and forms a combined evaluation. It can be prompted to perform for one file by parsing --file {file_name} or for all files in "3d-stacks/" by parsing --all. By parsing --model {path_to_model} you can choose which model you want to use, otherwise the model with the best validation loss is used as default, saved in "checkpoints/". The programs output is saved under "evaluation_results/" with a timestamp in order to distinguish different evaluations from one another. It saves a binary segmentation as a .nii.gz-file, a probabilty map as a .tif-file and a plot of the segmentation overlayed across the original image for the three middle slices as a .png for each file.

In the file visualize_results.py a visualisation of the three middle slices for the FMM-segmentations is created, similarily to the comparison created by "orthagonal_evaluation.py". These files are saved in "middle_slice_visualizations_{date_and_time}".

In "evaluation_metrics/compare_segmentations.py" evaluation metrics and comparisons of the FMM- and ML-segmentations are created.

The code is written in Python and mainly uses Tensorflow for ML and SimpleITK for FMM.